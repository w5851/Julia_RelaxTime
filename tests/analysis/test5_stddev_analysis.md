# 测试5标准差异常大的原因分析

## 问题
为什么测试5的标准差(0.015ms)比测试1(0.002ms)大得多？

## 实验数据对比

| 测试场景 | 平均值 | 标准差 | CV(变异系数) | 说明 |
|---------|-------|--------|-------------|------|
| **测试1**: 无缓存，相同参数 | 0.0119 ms | **0.0025 ms** | 0.21 | 基准 ✓ |
| **测试5**: 缓存0→1000增长 | 0.0127 ms | **0.0145 ms** | **1.14** | **5.8倍差异!** |
| 固定缓存1000→2000 | 0.0132 ms | **0.0028 ms** | 0.21 | 稳定 ✓ |
| 每次reset(缓存=1) | 0.0127 ms | **0.0027 ms** | 0.21 | 稳定 ✓ |

## 关键发现

### 1. 哈希表动态扩容是主因 ✓

**分段分析结果:**

| 缓存大小区间 | 平均值 | 标准差 | CV | 观察 |
|------------|-------|--------|----|----|
| 1-100 | 0.0129 ms | 0.0040 ms | 0.31 | 轻度波动 |
| 101-300 | 0.0127 ms | 0.0083 ms | 0.66 | 波动增加 |
| 301-600 | 0.0124 ms | 0.0021 ms | 0.17 | **最稳定** |
| **601-1000** | 0.0130 ms | **0.0219 ms** | **1.69** | **巨大波动!** |

**检测到的性能尖峰:**
- 第148次迭代: 0.1297 ms (平均值的10倍!)
- 第644次迭代: **0.4492 ms** (平均值的35倍!) ← **这是异常值的主要来源**

### 2. Julia Dict 的扩容机制

Julia的Dictionary在容量不足时会触发rehash：

```
容量序列: 16 → 32 → 64 → 128 → 256 → 512 → 1024 → 2048...
                              ↑          ↑      ↑
                          (148附近)  (644附近) (观察到的尖峰)
```

**扩容时的操作:**
1. 分配新的更大数组 (~几微秒)
2. 重新计算所有键的哈希值 (~几十微秒)
3. 重新插入所有键值对 (~几百微秒)
4. 释放旧数组

对于600+个条目的rehash，总时间可达 **0.4ms**！

## 为什么其他测试标准差小？

### 测试1 (无缓存): 稳定
- 每次都是纯计算，无哈希操作
- 标准差仅来自计算本身的波动

### 固定缓存1000→2000: 稳定  
- 初始容量已经是2048，不会再扩容
- 只有正常的哈希插入，无rehash事件

### 每次reset(缓存=1): 稳定
- 每次都是小哈希表(容量16)
- 永远不会扩容

### 测试5 (缓存0→1000): **极不稳定**
- **经历多次扩容**: 16→32→64→128→256→512→**1024**
- **第644次尤其慢**: 从512扩容到1024时，需要rehash 600+条目！

## 可视化对比

```
标准差放大图:

测试1  ┃██                               (0.0025 ms)
       ┃
测试5  ┃████████████████████████████████ (0.0145 ms) ← 5.8倍!
       ┃                    ↑
       ┃              主要来自第644次的0.45ms尖峰
固定   ┃██                               (0.0028 ms)
       ┃
reset  ┃██                               (0.0027 ms)
       ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
        0          0.005         0.010        0.015 ms
```

## 数学分析

### 标准差的计算

标准差衡量数据离散程度: σ = √[Σ(xi - μ)² / n]

**测试5中有几个极端异常值:**
- 第644次: 0.4492 ms (偏离平均值 +0.437 ms!)
- 第148次: 0.1297 ms (偏离平均值 +0.117 ms)

这两个异常值对标准差的贡献:
```
贡献 ≈ √[(0.437² + 0.117²) / 1000] 
     ≈ √[0.204 / 1000]
     ≈ 0.014 ms
```

**这解释了几乎全部的标准差差异！**

## 结论

测试5标准差大的原因是 **哈希表动态扩容导致的极端异常值**:

### 核心机制
1. ✅ **哈希表扩容**: Julia Dict在元素增加时会rehash所有条目
2. ✅ **扩容成本**: 与当前元素数量成正比（O(n)操作）
3. ✅ **触发点**: 128, 256, 512, **1024**... (2的幂)
4. ✅ **最慢的一次**: 第644次，从512扩到1024，需处理600+条目 → **0.45ms**

### 对比表

| 指标 | 测试1 (无缓存) | 测试5 (增长) | 原因 |
|-----|--------------|-------------|-----|
| 平均值 | 0.0119 ms | 0.0127 ms | 相近 ✓ |
| 最小值 | 0.0102 ms | 0.0112 ms | 相近 ✓ |
| **最大值** | 0.086 ms | **0.449 ms** | **5.2倍差异!** ← 扩容 |
| **标准差** | 0.0025 ms | **0.0145 ms** | **5.8倍差异!** ← 极端值 |
| **CV** | 0.21 | **1.14** | **5.4倍差异!** ← 不稳定 |

### 实际影响

**好消息**: 这个问题在实际应用中不是问题！

1. **扩容只发生一次**: 每个容量级别只扩容一次
2. **扩容后稳定**: 达到目标大小后性能稳定（见固定缓存测试）
3. **总体收益巨大**: 即使算上扩容成本，缓存仍带来12倍加速

### 真实应用场景

```
实际计算过程:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
第1-100次:   正常插入 (~12μs)
第101-200次: 正常插入 (~12μs)
...
第644次:     扩容! (~450μs)  ← 偶尔一次慢
第645-1000次: 正常插入 (~12μs)
第1001-10000次: 缓存命中! (~1μs) ← 之后全是高速
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

总体收益 = 大量缓存命中的加速 >> 偶尔扩容的成本
```

## 优化建议（如果需要）

如果想避免测试5的大标准差：

1. **预分配容量** (适合已知缓存大小):
```julia
const POLARIZATION_CACHE = Dict{PolarizationKey, Tuple{Float64, Float64}}()
sizehint!(POLARIZATION_CACHE, 10000)  # 预分配
```

2. **不使用reset_cache!的基准测试** (更准确的性能评估):
```julia
# 预填充缓存到目标大小
reset_cache!()
for i in 1:1000
    polarization_aniso_cached(...)  # 填充
end

# 然后测试固定大小缓存的性能
for i in 1001:2000
    # 测试代码...
end
```

3. **过滤异常值的统计** (更鲁棒的性能指标):
```julia
# 使用中位数和四分位距代替平均值和标准差
median_time = median(times)
iqr = quantile(times, 0.75) - quantile(times, 0.25)
```

## 总结

您的观察完全正确！测试5的标准差确实异常大，主要原因是：

- ❌ **不是** 哈希插入本身慢（只需2μs）
- ❌ **不是** 极化函数计算不稳定（测试1很稳定）
- ✅ **是** 哈希表动态扩容造成的极端异常值（第644次的0.45ms）

这个现象是Dict数据结构的正常行为，在实际应用中不影响缓存的整体收益。
